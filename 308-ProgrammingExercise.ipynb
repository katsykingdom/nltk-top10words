{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in this text (word:number of occurence):\n",
      "use 5\n",
      "read 5\n",
      "page 5\n",
      "elements 5\n",
      "devices 6\n",
      "using 7\n",
      "screen 8\n",
      "user 8\n",
      "finger 9\n",
      "users 13\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re #regex library\n",
    "import collections #library used to order dictionary\n",
    "from nltk.corpus import stopwords #library used to remove common words\n",
    "\n",
    "#tokenize input text\n",
    "f = open(\"data/text.txt\", \"r\")\n",
    "data = f.read()\n",
    "f.close()\n",
    "tokenizedText = nltk.word_tokenize(data)\n",
    "#tried the nltk tokenizer and also a simple split by spaces, the tokernizer worked better for words such as won't, can't\n",
    "#words = re.split(\"\\s\", data)\n",
    "\n",
    "#remove punctuation and common words\n",
    "length = len(tokenizedText)\n",
    "s=set(stopwords.words('english'))\n",
    "for i in range(length):\n",
    "    #remove punctuation with regex\n",
    "    tokenizedText[i] = re.sub(r'[^\\w\\s]','', tokenizedText[i])\n",
    "    #remove common english words with stopwords library such as 'the', 'on', 'et', etc. using stopwords library, generates a nested list\n",
    "    tokenizedText[i] = list(filter(lambda w: not w in s,tokenizedText[i].split()))\n",
    "\n",
    "#convert back nested list to list, from Stackoverflow\n",
    "tokenizedText = [value for sublist in tokenizedText for value in sublist]\n",
    "\n",
    "#remove leftover empty strings\n",
    "while(\"\" in tokenizedText) : \n",
    "    tokenizedText.remove(\"\") \n",
    "\n",
    "#find number of occurence of each word, from lecture\n",
    "counter = {}\n",
    "for i in tokenizedText:\n",
    "    if i in counter:\n",
    "        counter[i] += 1\n",
    "    else:\n",
    "        counter[i] = 1\n",
    "\n",
    "#sort list based on number of occurence of each word, keep only last 10 items\n",
    "sortedList = collections.OrderedDict(sorted(counter.items(), key=lambda x: x[1])[-10:]) #from StackOverflow\n",
    "\n",
    "#print final result\n",
    "print(\"Top words in this text (word:number of occurence):\")\n",
    "for i in sortedList:\n",
    "    print(i, sortedList[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
